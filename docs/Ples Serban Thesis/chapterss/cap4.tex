\chapter{Future Work}

This chapter outlines planned improvements and extensions to \emph{Cloud Class}, focusing on achieving 100\% integration test coverage, adding new features and third-party integrations, and enhancing deployment strategies for greater reliability and scalability.

% \section{Integration Testing}

% While unit tests validate individual modules in isolation, integration tests are essential to verify that the various microservices and infrastructure components work together correctly.  By exercising entire workflows—from HTTP or RabbitMQ entry points through background jobs and database interactions—we can catch misconfigurations, serialization mismatches, and contract regressions before they reach production.  Full integration test coverage will also give us confidence when refactoring core logic, evolving schemas, or extending APIs.

% To achieve this, we will:

% \begin{itemize}
%   \item Provision a \textbf{Docker-Compose-based test environment} that brings up all eight microservices alongside MongoDB (replica set), Redis, MinIO, and message brokers (RabbitMQ, BullMQ).  Automated scripts will then exercise HTTP and RabbitMQ endpoints using SuperTest or Newman.
%   \item Adopt \textbf{consumer-driven contract testing} (e.g.\ with Pact) so that each service’s producer and consumer tests enforce shared request/response schemas, preventing subtle API drifts.
%   \item Leverage \textbf{in-memory database instances} (MongoDB Memory Server, embedded Redis) and ephemeral queues to isolate test runs from production data, ensuring fast, repeatable feedback.
%   \item Integrate all integration suites into our \textbf{GitHub Actions pipeline}, splitting tests by service domain and running them in parallel to maintain rapid CI turnaround while enforcing coverage gates.
% \end{itemize}

\section{Integration Testing}

Integration tests go beyond individual modules to validate that my microservices and supporting infrastructure collaborate seamlessly. By running full end-to-end scenarios—from incoming HTTP or message-queue requests through background-job execution and database operations—I can uncover issues such as misrouted messages, data-format mismatches, or broken service contracts before they affect real users. Achieving 100\% coverage in integration tests will also give me the confidence to refactor core components, evolve data schemas, and extend APIs without fear of unintended side effects.

To put this into practice, I will:

\begin{itemize}
  \item Set up a \textbf{Docker-Compose-based test environment} that launches all eight microservices alongside MongoDB (configured as a replica set), Redis, MinIO, and both RabbitMQ and BullMQ brokers.  Automated scripts will then invoke HTTP endpoints with SuperTest and publish to queues via Newman to exercise every part of the system.
  \item Introduce \textbf{consumer-driven contract testing} (for example, with Pact) so that each service explicitly verifies the schemas it expects from its peers, preventing subtle API drifts and ensuring compatibility across deployments.
  \item Use \textbf{in-memory database instances} (such as MongoDB Memory Server and an embedded Redis) together with ephemeral queue brokers to keep tests fast, isolated, and free from interference with production data.
  \item Integrate all integration suites into my \textbf{GitHub Actions pipeline}, organizing tests by service domain and running them in parallel.  This approach will maintain quick feedback for development while enforcing strict coverage thresholds before merging changes.
\end{itemize}



\section{New Features and Integrations}

I plan to introduce two new capabilities—Google Calendar synchronization and a built-in video call feature.  In our microservice architecture, this can be as straightforward as adding two dedicated services alongside the existing ones.

\subsection{Study Session Feature}

The Study Session service will let users create, join, and manage collaborative study meetings. It will provide endpoints such as \texttt{/study-sessions} for listing upcoming sessions and \texttt{/study-sessions/:id/join} for RSVP-style participation. Internally, it will store session details—topic, start and end times, participant list—and emit events whenever sessions are created, updated, or canceled. Other services (like Calendar and Video Call) will subscribe to these events to keep in sync.

\subsection{Google Calendar Integration}

The Calendar microservice will serve as a bridge between \emph{Cloud Class} and the Google Calendar API.  Its responsibilities include handling OAuth2 flows, synchronizing events, and delivering calendar data to other services in our platform.

First, I will define a narrow REST API within the new service for operations such as \texttt{GET /calendar/events}, \texttt{POST /calendar/events}, and \texttt{DELETE /calendar/events}.  Internally, the service will manage user credentials and tokens in a secure store, refreshing them as needed via the Google OAuth2 endpoint.  A background scheduler will poll or subscribe to calendar push notifications, ensuring that any changes in a user`s Google Calendar are reflected in our system within seconds.  When a user schedules a class, the Class microservice will emit an event (via RabbitMQ), which the Calendar service will consume to create or update the corresponding Google Calendar entry.  Error handling and retry logic will ensure resilience against transient API failures.

\subsection{Video Call Service}

The Video Call microservice will handle session negotiation and signaling for real-time audio/video between users.  To do this, I will expose endpoints such as \texttt{POST /calls/create}, \texttt{POST /calls/join}, and a WebSocket or Socket.IO namespace for exchanging SDP offers, ICE candidates, and call metadata.

Under the hood, the service will integrate with a WebRTC media server (for example, a managed service or an open-source solution like Janus or mediasoup) to handle NAT traversal (STUN/TURN) and media routing.  Authentication tokens will be verified by consulting the Auth microservice, ensuring that only authorized users can start or join sessions.  Call session state—participants, start/end times, and recording toggles—will be persisted to MongoDB, enabling audit trails and post-call processing.  By isolating all signaling and media logic in a dedicated microservice, I can independently scale video infrastructure (e.g.\ TURN servers) according to usage patterns, without impacting the performance of chat, notification, or storage services.

All three of these new microservices will be developed using the same technology stack (NestJS, TypeScript, Docker).
\section{Deployment}

Ensuring the reliable operation of \emph{Cloud Class} requires a considered deployment strategy composed of three key elements: database resilience, container orchestration, and traffic management.

\subsection{MongoDB Replication}

MongoDB will be deployed as a three-node replica set to provide data redundancy and automatic failover. In the event that the primary node becomes unavailable, a secondary node will assume the primary role without manual intervention, thereby minimizing downtime. Read preferences will be configured to direct reporting and analytical queries to secondary nodes, which helps to distribute read load and preserve primary performance. Additionally, the built-in change stream functionality will be leveraged to support real-time features—such as notifications and audit logging—while avoiding unnecessary complexity in the application layer.

\subsection{Containerization and Orchestration}

All services are packaged as Docker containers to ensure consistency across development, testing, and production environments. Two orchestration platforms will be evaluated:

\paragraph{Docker Swarm}  
Offers a straightforward setup with native clustering, service replication, and rolling updates. Its simplicity makes it well suited for smaller teams or early‐stage deployments.

\paragraph{Kubernetes}  
Provides a more comprehensive feature set, including declarative resource definitions, automated scaling through the Horizontal Pod Autoscaler, and support for stateful workloads via StatefulSets. Its extensive ecosystem—encompassing service meshes, GitOps tools, and monitoring solutions—makes it ideal for large‐scale, production‐grade environments.

The choice between these platforms will be guided by the desired balance between operational simplicity and the need for advanced scalability and resilience features.

\subsection{Load Balancing and Service Replication}

An ingress controller (for example, NGINX or Traefik) will be deployed to manage external traffic. This component will perform TLS termination, path-based routing, and distribute incoming requests evenly across available service replicas. Health checks and readiness probes will ensure that only healthy instances receive traffic, and rolling-update or canary deployment strategies will minimize user impact during releases. Finally, autoscaling policies—based on metrics such as CPU utilization, memory consumption, and application-specific indicators—will enable the system to adjust its capacity dynamically, ensuring consistent performance while optimizing infrastructure costs.  
